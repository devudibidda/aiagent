# üéØ Quick Reference Card - AI Compliance Agent

## üö® ERROR: "llama runner process has terminated"

**INSTANT FIX (3 steps):**
```bash
# Terminal 1 - Start Ollama
ollama serve

# Terminal 2 - Check status
curl http://localhost:11434/api/tags

# Terminal 3 - Run app
OLLAMA_MODEL=neural-chat python -m ai_compliance_agent.ui_gradio
```

**If still failing:**
- ‚úÖ Ensure 8GB+ free RAM: `free -h`
- ‚úÖ Use lighter model: `OLLAMA_MODEL=neural-chat` in `.env`
- ‚úÖ Monitor memory: `watch -n 1 free -h`

---

## ‚ö° START IN 30 SECONDS

```bash
# Terminal 1
ollama serve

# Terminal 2 (wait 3 seconds)
OLLAMA_MODEL=neural-chat python -m ai_compliance_agent.ui_gradio

# Browser
http://127.0.0.1:7860
```

---

## üìã MODES OF OPERATION

### 1. Web UI (Recommended) ‚≠ê
```bash
python -m ai_compliance_agent.ui_gradio
# ‚Üí http://127.0.0.1:7860
# Best for: Interactive analysis, non-technical users
```

### 2. Python API
```python
from ai_compliance_agent.agent_pipeline import ComplianceAgent
from pathlib import Path

agent = ComplianceAgent()
result = agent.analyse(
    pdf_id="./local_pdfs/document.pdf",
    knowledge_base_path=Path("./ai_compliance_agent/knowledge_base")
)
print(result["analysis"])
```

### 3. Batch Processing
```python
from concurrent.futures import ThreadPoolExecutor

pdfs = ["doc1.pdf", "doc2.pdf", "doc3.pdf"]
with ThreadPoolExecutor(max_workers=2) as executor:
    results = [
        executor.submit(agent.analyse, pdf, kb_path)
        for pdf in pdfs
    ]
```

---

## üîß CONFIGURATION

### Environment Variables (.env)
```bash
# ‚úÖ REQUIRED
OLLAMA_MODEL=neural-chat

# ‚ùì Optional (OAuth2 PDF API)
API_BASE_URL=https://api.example.com
TOKEN_URL=https://auth.example.com/oauth/token
CLIENT_ID=your_client_id
CLIENT_SECRET=your_client_secret

# Optional (paths)
DOWNLOAD_DIR=./ai_compliance_agent/tmp_downloads
KNOWLEDGE_BASE_DIR=./ai_compliance_agent/knowledge_base
LOCAL_PDF_DIR=./ai_compliance_agent/local_pdfs
```

### Directories
```
knowledge_base/    ‚Üí Standard PDFs
local_pdfs/        ‚Üí Local test files
tmp_downloads/     ‚Üí Downloaded PDFs
```

---

## ‚úÖ QUICK CHECKLIST

- [ ] Python 3.11.9+
- [ ] Virtual env active
- [ ] 65+ packages installed
- [ ] Ollama ready
- [ ] Port 7860 free
- [ ] Knowledge base setup

---

## üÜò QUICK FIXES

| Problem | Fix |
|---------|-----|
| "Module not found" | ‚úÖ Already fixed |
| Ollama error | Run: `ollama serve mistral` |
| Port 7860 in use | `taskkill /PID <ID> /F` |
| Slow | Use: `OLLAMA_MODEL=neural-chat` |
| Memory error | Process one file at a time |

---

## üìö DOCUMENTATION

- **QUICK_START_GUIDE.md** - Complete setup
- **ADVANCED_GUIDE.md** - Production deployment
- **RUN_COMMANDS.md** - All commands
- **SCRIPT_ANALYSIS.md** - Technical details

---

## üéØ TYPICAL USAGE

```python
from ai_compliance_agent.agent_pipeline import ComplianceAgent
from pathlib import Path

# Initialize
agent = ComplianceAgent()

# Analyze
result = agent.analyse(
    pdf_id="document.pdf",
    knowledge_base_path=Path("knowledge_base")
)

# Results contain:
# - analysis (main report)
# - document_summary
# - knowledge_base_summary
# - sources (retrieved context)
```

---

## üöÄ STATUS: ‚úÖ READY

**All issues fixed. Ready to execute now!**

---

## üì± FILES CREATED FOR YOU

```
‚úÖ FINAL_SUMMARY.md         ‚Üí Start here
‚úÖ RUN_COMMANDS.md          ‚Üí Copy-paste commands
‚úÖ QUICK_START_GUIDE.md     ‚Üí Step-by-step setup
‚úÖ ADVANCED_GUIDE.md        ‚Üí Production guide
‚úÖ SCRIPT_ANALYSIS.md       ‚Üí Technical details
```

---

**Let's go! üéâ**

Run these commands now:
```
ollama serve mistral &
python -m ai_compliance_agent.ui_gradio
```
